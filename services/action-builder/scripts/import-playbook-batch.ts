#!/usr/bin/env npx tsx
/**
 * Import Playbook Batch Runner
 *
 * Reads batch summary JSON generated by crawl-playbook-batch.ts and
 * imports each entry by calling test/e2e/import-playbook.ts in order.
 *
 * Usage:
 *   pnpm -C services/action-builder import:batch
 *   pnpm -C services/action-builder import:batch -- --summary output/batch/crawl_playbook_batch_summary_xxx.json
 *   pnpm -C services/action-builder import:batch -- --stop-on-error
 *   pnpm -C services/action-builder import:batch -- --dry-run
 *
 * Notes:
 * - Defaults to the latest crawl_playbook_batch_summary_*.json in ./output/batch/
 * - Only imports entries with status=completed and existing jsonPath
 */

import fs from 'node:fs'
import path from 'node:path'
import { spawn } from 'node:child_process'
import { fileURLToPath } from 'node:url'

type CrawlBatchSummary = {
  metadata?: {
    createdAt?: string
    total?: number
    completed?: number
    failed?: number
    timeout?: number
    batchArgs?: string[]
  }
  results: Array<{
    url: string
    status: 'completed' | 'failed' | 'timeout' | string
    jsonPath?: string
    yamlPath?: string
    error?: string
  }>
}

type ImportItemResult = {
  url: string
  status: 'skipped' | 'imported' | 'failed'
  jsonPath?: string
  exitCode: number | null
  signal: NodeJS.Signals | null
  startedAt: string
  finishedAt: string
  durationMs: number
  error?: string
}

type ImportBatchSummary = {
  metadata: {
    createdAt: string
    sourceSummaryPath: string
    totalCandidates: number
    imported: number
    failed: number
    skipped: number
    args: string[]
  }
  results: ImportItemResult[]
}

function nowIso(): string {
  return new Date().toISOString()
}

function timestampForFile(): string {
  return new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19)
}

function parseArgValue(args: string[], name: string): string | undefined {
  const idx = args.indexOf(name)
  if (idx === -1) return undefined
  return args[idx + 1]
}

function hasFlag(args: string[], name: string): boolean {
  return args.includes(name)
}

function ensureDir(dirPath: string) {
  fs.mkdirSync(dirPath, { recursive: true })
}

function getActionBuilderRoot(): string {
  // scripts/ -> action-builder root is one level up
  const here = path.dirname(fileURLToPath(import.meta.url))
  return path.resolve(here, '..')
}

function resolveTsxPath(actionBuilderRoot: string): string {
  const tsxPath = path.join(actionBuilderRoot, 'node_modules', '.bin', 'tsx')
  if (fs.existsSync(tsxPath)) return tsxPath
  return 'tsx'
}

function resolveSummaryPath(actionBuilderRoot: string, summaryArg?: string): string {
  if (summaryArg) {
    return path.isAbsolute(summaryArg)
      ? summaryArg
      : path.resolve(actionBuilderRoot, summaryArg)
  }

  const batchDir = path.resolve(actionBuilderRoot, 'output', 'batch')
  if (!fs.existsSync(batchDir)) {
    throw new Error(
      `batch dir not found: ${batchDir}. Run crawl:batch first to generate summary, or use --summary to specify file`
    )
  }

  const files = fs
    .readdirSync(batchDir)
    .filter((f) => f.startsWith('crawl_playbook_batch_summary_') && f.endsWith('.json'))
    .map((f) => path.join(batchDir, f))

  if (files.length === 0) {
    throw new Error(
      `no summary file found in ${batchDir}. Run crawl:batch first, or use --summary to specify file`
    )
  }

  files.sort((a, b) => fs.statSync(b).mtimeMs - fs.statSync(a).mtimeMs)
  return files[0]
}

function loadCrawlBatchSummary(summaryPath: string): CrawlBatchSummary {
  const raw = fs.readFileSync(summaryPath, 'utf-8')
  const parsed = JSON.parse(raw) as CrawlBatchSummary
  if (!parsed || !Array.isArray(parsed.results)) {
    throw new Error(`invalid summary json: results[] missing in ${summaryPath}`)
  }
  return parsed
}

type ImportRunSummaryFile = {
  metadata?: {
    createdAt?: string
    sourceSummaryPath?: string
    totalCandidates?: number
    imported?: number
    failed?: number
    skipped?: number
    args?: string[]
  }
  results: ImportItemResult[]
}

function loadImportRunSummary(summaryPath: string): ImportRunSummaryFile {
  const raw = fs.readFileSync(summaryPath, 'utf-8')
  const parsed = JSON.parse(raw) as ImportRunSummaryFile
  if (!parsed || !Array.isArray(parsed.results)) {
    throw new Error(`invalid import summary json: results[] missing in ${summaryPath}`)
  }
  return parsed
}

async function runImportOne(options: {
  actionBuilderRoot: string
  tsxPath: string
  url: string
  jsonPath: string
  dryRun: boolean
}): Promise<ImportItemResult> {
  const startedAt = nowIso()
  const t0 = Date.now()

  if (options.dryRun) {
    return {
      url: options.url,
      status: 'skipped',
      jsonPath: options.jsonPath,
      exitCode: 0,
      signal: null,
      startedAt,
      finishedAt: nowIso(),
      durationMs: 0,
    }
  }

  const childArgs = ['test/e2e/import-playbook.ts', options.jsonPath]

  console.log('\n' + '-'.repeat(80))
  console.log(`üì• Import: ${options.url}`)
  console.log(`‚ñ∂Ô∏è  Run: ${options.tsxPath} ${childArgs.join(' ')}`)
  console.log('-'.repeat(80))

  const child = spawn(options.tsxPath, childArgs, {
    cwd: options.actionBuilderRoot,
    env: process.env,
    stdio: 'inherit',
  })

  const { exitCode, signal } = await new Promise<{
    exitCode: number | null
    signal: NodeJS.Signals | null
  }>((resolve) => {
    child.on('close', (code, sig) => resolve({ exitCode: code, signal: sig }))
  })

  const finishedAt = nowIso()
  const durationMs = Date.now() - t0

  return {
    url: options.url,
    status: exitCode === 0 ? 'imported' : 'failed',
    jsonPath: options.jsonPath,
    exitCode,
    signal,
    startedAt,
    finishedAt,
    durationMs,
    error:
      exitCode === 0
        ? undefined
        : `import-playbook exited with code ${exitCode}${signal ? ` (signal=${signal})` : ''}`,
  }
}

async function main() {
  const argv = process.argv.slice(2)

  const summaryArg = parseArgValue(argv, '--summary')
  const retryFromArg = parseArgValue(argv, '--retry-from')
  const dryRun = hasFlag(argv, '--dry-run')
  const stopOnError = hasFlag(argv, '--stop-on-error')

  const actionBuilderRoot = getActionBuilderRoot()
  const tsxPath = resolveTsxPath(actionBuilderRoot)

  const importSummaryPath = path.resolve(
    actionBuilderRoot,
    'output',
    'batch',
    `import_playbook_batch_summary_${timestampForFile()}.json`
  )
  ensureDir(path.dirname(importSummaryPath))

  // Mode A: retry failed imports from a previous import summary
  if (retryFromArg) {
    const retryFromPath = path.isAbsolute(retryFromArg)
      ? retryFromArg
      : path.resolve(actionBuilderRoot, retryFromArg)

    const prev = loadImportRunSummary(retryFromPath)
    const failedItems = prev.results.filter((r) => r.status === 'failed' && r.jsonPath)

    console.log('='.repeat(80))
    console.log('Import Playbook - Batch Runner (Retry Failed)')
    console.log('='.repeat(80))
    console.log(`Action Builder Root: ${actionBuilderRoot}`)
    console.log(`Retry From: ${retryFromPath}`)
    console.log(`Failed items: ${failedItems.length}/${prev.results.length}`)
    console.log(`Dry run: ${dryRun ? 'true' : 'false'}`)
    console.log(`Stop on error: ${stopOnError ? 'true' : 'false'}`)
    console.log(`Output Summary: ${importSummaryPath}`)
    console.log('='.repeat(80))

    const results: ImportItemResult[] = []
    for (const item of failedItems) {
      const jsonPath = item.jsonPath!
      const absJsonPath = path.isAbsolute(jsonPath)
        ? jsonPath
        : path.resolve(actionBuilderRoot, jsonPath)

      if (!fs.existsSync(absJsonPath)) {
        const r: ImportItemResult = {
          url: item.url,
          status: 'failed',
          jsonPath: absJsonPath,
          exitCode: 1,
          signal: null,
          startedAt: nowIso(),
          finishedAt: nowIso(),
          durationMs: 0,
          error: `json file not found: ${absJsonPath}`,
        }
        results.push(r)
        console.error(`‚ùå ${r.error}`)
        if (stopOnError) break
        continue
      }

      const r = await runImportOne({
        actionBuilderRoot,
        tsxPath,
        url: item.url,
        jsonPath: absJsonPath,
        dryRun,
      })
      results.push(r)

      const icon = r.status === 'imported' ? '‚úÖ' : r.status === 'skipped' ? '‚è≠Ô∏è' : '‚ùå'
      console.log(`\n${icon} Retry import done: ${item.url} (${(r.durationMs / 1000).toFixed(1)}s)`)
      if (r.error) console.log(`   Error: ${r.error}`)
      if (stopOnError && r.status === 'failed') break
    }

    const batch: ImportBatchSummary = {
      metadata: {
        createdAt: nowIso(),
        sourceSummaryPath: prev.metadata?.sourceSummaryPath ?? '(unknown)',
        totalCandidates: failedItems.length,
        imported: results.filter((r) => r.status === 'imported').length,
        failed: results.filter((r) => r.status === 'failed').length,
        skipped: results.filter((r) => r.status === 'skipped').length,
        args: argv,
      },
      results,
    }

    fs.writeFileSync(importSummaryPath, JSON.stringify(batch, null, 2), 'utf-8')

    console.log('\n' + '='.repeat(80))
    console.log('‚úÖ Retry Import Batch Summary Saved')
    console.log(`üìÅ ${importSummaryPath}`)
    console.log(
      `Stats: imported=${batch.metadata.imported}, failed=${batch.metadata.failed}, skipped=${batch.metadata.skipped}, candidates=${batch.metadata.totalCandidates}`
    )
    console.log('='.repeat(80))

    if (batch.metadata.failed > 0) process.exit(1)
    return
  }

  // Mode B: import from a crawl batch summary
  const summaryPath = resolveSummaryPath(actionBuilderRoot, summaryArg)
  const crawlSummary = loadCrawlBatchSummary(summaryPath)

  const candidates = crawlSummary.results.filter(
    (r) => r.status === 'completed' && typeof r.jsonPath === 'string' && r.jsonPath.length > 0
  )

  console.log('='.repeat(80))
  console.log('Import Playbook - Batch Runner')
  console.log('='.repeat(80))
  console.log(`Action Builder Root: ${actionBuilderRoot}`)
  console.log(`Source Summary: ${summaryPath}`)
  console.log(`Candidates: ${candidates.length}/${crawlSummary.results.length}`)
  console.log(`Dry run: ${dryRun ? 'true' : 'false'}`)
  console.log(`Stop on error: ${stopOnError ? 'true' : 'false'}`)
  console.log(`Output Summary: ${importSummaryPath}`)
  console.log('='.repeat(80))

  const results: ImportItemResult[] = []

  for (const item of crawlSummary.results) {
    if (item.status !== 'completed' || !item.jsonPath) {
      results.push({
        url: item.url,
        status: 'skipped',
        jsonPath: item.jsonPath,
        exitCode: 0,
        signal: null,
        startedAt: nowIso(),
        finishedAt: nowIso(),
        durationMs: 0,
        error: item.status !== 'completed' ? `skipped: crawl status=${item.status}` : 'skipped: jsonPath missing',
      })
      continue
    }

    const jsonPath = path.isAbsolute(item.jsonPath)
      ? item.jsonPath
      : path.resolve(actionBuilderRoot, item.jsonPath)

    if (!fs.existsSync(jsonPath)) {
      const r: ImportItemResult = {
        url: item.url,
        status: 'failed',
        jsonPath,
        exitCode: 1,
        signal: null,
        startedAt: nowIso(),
        finishedAt: nowIso(),
        durationMs: 0,
        error: `json file not found: ${jsonPath}`,
      }
      results.push(r)
      console.error(`‚ùå ${r.error}`)
      if (stopOnError) break
      continue
    }

    const r = await runImportOne({
      actionBuilderRoot,
      tsxPath,
      url: item.url,
      jsonPath,
      dryRun,
    })
    results.push(r)

    const icon = r.status === 'imported' ? '‚úÖ' : r.status === 'skipped' ? '‚è≠Ô∏è' : '‚ùå'
    console.log(`\n${icon} Import done: ${item.url} (${(r.durationMs / 1000).toFixed(1)}s)`)
    if (r.error) console.log(`   Error: ${r.error}`)

    if (stopOnError && r.status === 'failed') break
  }

  const batch: ImportBatchSummary = {
    metadata: {
      createdAt: nowIso(),
      sourceSummaryPath: summaryPath,
      totalCandidates: candidates.length,
      imported: results.filter((r) => r.status === 'imported').length,
      failed: results.filter((r) => r.status === 'failed').length,
      skipped: results.filter((r) => r.status === 'skipped').length,
      args: argv,
    },
    results,
  }

  fs.writeFileSync(importSummaryPath, JSON.stringify(batch, null, 2), 'utf-8')

  console.log('\n' + '='.repeat(80))
  console.log('‚úÖ Import Batch Summary Saved')
  console.log(`üìÅ ${importSummaryPath}`)
  console.log(
    `Stats: imported=${batch.metadata.imported}, failed=${batch.metadata.failed}, skipped=${batch.metadata.skipped}, candidates=${batch.metadata.totalCandidates}`
  )
  console.log('='.repeat(80))

  if (batch.metadata.failed > 0) process.exit(1)
}

main().catch((error) => {
  console.error('Fatal error:', error)
  process.exit(1)
})

